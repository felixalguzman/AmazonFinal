{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "11Xrk_oyY5g19ht85HC7_rJ1nVSTgEwXx",
      "authorship_tag": "ABX9TyO5mlWWzviUF34YAp4lvgtC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixalguzman/AmazonFinal/blob/master/keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "294EuAOzYSBS",
        "colab_type": "code",
        "outputId": "b1a5b5ea-e583-434a-9114-75e610c8008d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79g3zT74ZVsB",
        "colab_type": "code",
        "outputId": "0463046c-22e4-4ae2-d146-cde03241ea94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"es_core_news_sm\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKXQ5CNMZ0Tl",
        "colab_type": "code",
        "outputId": "2793fa00-ca93-4248-b6b6-259aaa44a50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Loads the spacy en model into a python object\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "\n",
        "def separar_oracion_tokens(oracion: str):\n",
        "    return [token.text for token in nlp(oracion)]\n",
        "\n",
        "\n",
        "print('tokens? {}'.format(separar_oracion_tokens('Qué es el contrato de trabajo?')))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokens? ['Qué', 'es', 'el', 'contrato', 'de', 'trabajo', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPpvrmWz2XY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "6ec9844c-4778-43e5-f64d-961f7045c990"
      },
      "source": [
        "!pip install gensim\n",
        "from gensim.models.keyedvectors import  KeyedVectors\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.10.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.18.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.12.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim) (1.0.3)\n",
            "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim) (1.7.2)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim) (0.4.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.15.31)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim) (46.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim) (4.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->smart-open>=1.2.1->gensim) (2.8.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim) (1.51.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "783e21a5-e946-46d7-c50b-3c5a129402db",
        "id": "Y27i7NUZX_r2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "import yaml\n",
        "from tensorflow.keras import layers, activations, models, preprocessing, utils\n",
        "from gensim.models.keyedvectors import  KeyedVectors\n",
        "\n",
        "import re\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "print(\"tensor version {}\".format(tf.version.VERSION))\n",
        "\n",
        "dir_path = \"/content/drive/My Drive/\"\n",
        "files_list = os.listdir(dir_path + os.sep)\n",
        "ruta_glove = \"/content/drive/My Drive/fasttext-sbwc.vec.gz\"\n",
        "\n",
        "filtros = '!\"#$%&()*+-/<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "\n",
        "questions = list()\n",
        "resp = list()\n",
        "answers = list()\n",
        "vocab = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "print(\"Archivos a entrenar: {}\".format(files_list))\n",
        "for filepath in files_list:\n",
        "    if filepath.endswith(\".yaml\"):\n",
        "        stream = open(dir_path + os.sep + filepath, \"rb\")\n",
        "        docs = yaml.safe_load(stream)\n",
        "        conversations = docs[\"conversaciones\"]\n",
        "        for con in conversations:\n",
        "            input_text = con[0]\n",
        "            if len(con) > 2:\n",
        "                pregunta = input_text\n",
        "                pregunta = pregunta.lower()\n",
        "                # pregunta = re.sub(\"[^a-zA-Z]\", \" \", pregunta)\n",
        "                questions.append(pregunta)\n",
        "                res = con[1:]\n",
        "\n",
        "                ans = \"\"\n",
        "                for rep in res:\n",
        "                    r = str(rep).lower()\n",
        "                    # r = re.sub(\"[^a-zA-Z]\", \" \", rep)\n",
        "                    ans += \" \" + r\n",
        "                resp.append(ans)\n",
        "            elif len(con) > 1:\n",
        "                questions.append(input_text)\n",
        "                target_text = con[1]\n",
        "                resp.append(target_text)\n",
        "\n",
        "                for char in separar_oracion_tokens(input_text):\n",
        "                    if char not in input_characters:\n",
        "                        input_characters.add(char)\n",
        "                for char in separar_oracion_tokens(target_text):\n",
        "                    if char not in target_characters:\n",
        "                        target_characters.add(char)\n",
        "\n",
        "\n",
        "answers_with_tags = list()\n",
        "for i in range(len(resp)):\n",
        "    if type(resp[i]) == str:\n",
        "        answers_with_tags.append(resp[i])\n",
        "    else:\n",
        "        questions.pop(i)\n",
        "\n",
        "for i in range(len(answers_with_tags)):\n",
        "    answers.append(\"<START> \" + answers_with_tags[i] + \" <END>\")\n",
        "\n",
        "palabras = set()\n",
        "palabras.add('start')\n",
        "palabras.add('end')\n",
        "palabras = palabras.union(target_characters)\n",
        "palabras = palabras.union(input_characters)\n",
        "palabras = sorted(list(palabras))\n",
        "tokenizer = preprocessing.text.Tokenizer(filters=filtros)\n",
        "tokenizer.fit_on_texts(palabras)\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "print(\"vocab size : {}\".format(VOCAB_SIZE))\n",
        "\n",
        "for word in tokenizer.word_index:\n",
        "    vocab.append(word)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# encoder_input_data\n",
        "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
        "padded_questions = preprocessing.sequence.pad_sequences(\n",
        "    tokenized_questions, maxlen=maxlen_questions, padding=\"post\"\n",
        ")\n",
        "encoder_input_data = np.array(padded_questions)\n",
        "print(encoder_input_data.shape, maxlen_questions)\n",
        "\n",
        "# decoder_input_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
        "padded_answers = preprocessing.sequence.pad_sequences(\n",
        "    tokenized_answers, maxlen=maxlen_answers, padding=\"post\"\n",
        ")\n",
        "decoder_input_data = np.array(padded_answers)\n",
        "print(decoder_input_data.shape, maxlen_answers)\n",
        "\n",
        "# decoder_output_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "for i in range(len(tokenized_answers)):\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "padded_answers = preprocessing.sequence.pad_sequences(\n",
        "    tokenized_answers, maxlen=maxlen_answers, padding=\"post\"\n",
        ")\n",
        "onehot_answers = utils.to_categorical(padded_answers, VOCAB_SIZE)\n",
        "decoder_output_data = np.array(onehot_answers)\n",
        "print(decoder_output_data.shape)\n",
        "\n",
        "# Saving all the arrays to storage\n",
        "np.save(\"enc_in_data.npy\", encoder_input_data)\n",
        "np.save(\"dec_in_data.npy\", decoder_input_data)\n",
        "np.save(\"dec_tar_data.npy\", decoder_output_data)\n",
        "\n",
        "word_vectors = KeyedVectors.load_word2vec_format(ruta_glove)\n",
        "\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, 300))\n",
        "\n",
        "for i, word in enumerate(vocab):\n",
        "  try:\n",
        "    embedding_vector = word_vectors.get_vector(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "  except KeyError as e:\n",
        "    print('No esta en glove: {}'.format(e))   \n",
        "# embeddings_index = {}\n",
        "# with open('glove.6B.50d.txt', encoding='utf-8') as f:\n",
        "#     for line in f:\n",
        "#         values = line.split()\n",
        "#         word = values[0]\n",
        "#         coefs = np.asarray(values[1:], dtype='float32')\n",
        "#         embeddings_index[word] = coefs\n",
        "#     f.close()\n",
        "\n",
        "# print(\"Glove Loded!\")\n",
        "\n",
        "\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "embedding_layer_in = tf.keras.layers.Embedding( input_dim=VOCAB_SIZE, output_dim=300, weights=[embedding_matrix], mask_zero=True)\n",
        "encoder_embedding = embedding_layer_in(\n",
        "    encoder_inputs\n",
        ")\n",
        "# encoder_embedding.set_weights([embedding_matrix])\n",
        "\n",
        "# encoder_embedding.set_weights([])\n",
        "encoder_outputs, state_h, state_c = tf.keras.layers.LSTM(300, return_state=True)(\n",
        "    encoder_embedding\n",
        ")\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "embedding_layer_de = tf.keras.layers.Embedding( input_dim=VOCAB_SIZE, output_dim=300, weights=[embedding_matrix], mask_zero=True)\n",
        "decoder_embedding = embedding_layer_de(\n",
        "    decoder_inputs\n",
        ")\n",
        "\n",
        "decoder_lstm = tf.keras.layers.LSTM(300, return_state=True, return_sequences=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = tf.keras.layers.Dense(\n",
        "    VOCAB_SIZE, activation=tf.keras.activations.softmax\n",
        ")\n",
        "output = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor version 2.2.0-rc2\n",
            "Archivos a entrenar: ['Google Fotos', \"Apk's & Games\", 'Documents', 'Enpass', 'MyBoy', 'Bluecoins', 'Untitled (2)', 'Classroom', 'Análisis de Data', 'Redes', 'Tareas', 'arc-history-export.json', 'Copy of StarWarsRacerV2_2018.zip', 'raspberry', 'Legaldo Privacy Policy.gdoc', 'Glosario 1-Vacio.gdoc', 'Guia de Lectura para el Primer Parcial HIP.gdoc', 'LEGALBOT.docx.gdoc', 'Glosario 2do Parcial-Linea.gdoc', 'Untitled document.gdoc', 'Registros Weintek-Swedish.gsheet', 'Anyfile Notepad Files', 'Estadisticas.xlsx', 'app.barcam.org.gdoc', 'fxlauncher', 'Untitled (1)', 'Untitled', 'Colab Notebooks', 'Swedish peticiones.gdoc', 'Sistema de facturacion.drawio', 'bot.yaml', 'variaciones2.yaml', 'variaciones1.yaml', 'preguntas.yaml', 'model.h5', 'Proyecto final', 'fasttext-sbwc.300k.vec.gz', 'fasttext-sbwc.vec.gz']\n",
            "vocab size : 2915\n",
            "(1151, 38) 38\n",
            "(1151, 321) 321\n",
            "(1151, 321, 2915)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "No esta en glove: \"word 'ct.' not in vocabulary\"\n",
            "No esta en glove: \"word ';' not in vocabulary\"\n",
            "No esta en glove: \"word '100' not in vocabulary\"\n",
            "No esta en glove: \"word '35' not in vocabulary\"\n",
            "No esta en glove: \"word '38' not in vocabulary\"\n",
            "No esta en glove: \"word '91' not in vocabulary\"\n",
            "No esta en glove: \"word '8' not in vocabulary\"\n",
            "No esta en glove: \"word 'empleador.' not in vocabulary\"\n",
            "No esta en glove: \"word 'etc.' not in vocabulary\"\n",
            "No esta en glove: \"word 'siguiente:' not in vocabulary\"\n",
            "No esta en glove: \"word 'trabajador.' not in vocabulary\"\n",
            "No esta en glove: \"word ',' not in vocabulary\"\n",
            "No esta en glove: \"word '.' not in vocabulary\"\n",
            "No esta en glove: \"word '..' not in vocabulary\"\n",
            "No esta en glove: \"word '02' not in vocabulary\"\n",
            "No esta en glove: \"word '04' not in vocabulary\"\n",
            "No esta en glove: \"word '05' not in vocabulary\"\n",
            "No esta en glove: \"word '07' not in vocabulary\"\n",
            "No esta en glove: \"word '08' not in vocabulary\"\n",
            "No esta en glove: \"word '1' not in vocabulary\"\n",
            "No esta en glove: \"word '1,000' not in vocabulary\"\n",
            "No esta en glove: \"word '1.trabajadores' not in vocabulary\"\n",
            "No esta en glove: \"word '10' not in vocabulary\"\n",
            "No esta en glove: \"word '.art' not in vocabulary\"\n",
            "No esta en glove: \"word '101' not in vocabulary\"\n",
            "No esta en glove: \"word '102' not in vocabulary\"\n",
            "No esta en glove: \"word '103' not in vocabulary\"\n",
            "No esta en glove: \"word '109' not in vocabulary\"\n",
            "No esta en glove: \"word '11.91' not in vocabulary\"\n",
            "No esta en glove: \"word '110' not in vocabulary\"\n",
            "No esta en glove: \"word '111' not in vocabulary\"\n",
            "No esta en glove: \"word '113' not in vocabulary\"\n",
            "No esta en glove: \"word '114' not in vocabulary\"\n",
            "No esta en glove: \"word '115' not in vocabulary\"\n",
            "No esta en glove: \"word '12' not in vocabulary\"\n",
            "No esta en glove: \"word '123' not in vocabulary\"\n",
            "No esta en glove: \"word '125' not in vocabulary\"\n",
            "No esta en glove: \"word '13' not in vocabulary\"\n",
            "No esta en glove: \"word '135' not in vocabulary\"\n",
            "No esta en glove: \"word '14' not in vocabulary\"\n",
            "No esta en glove: \"word '141' not in vocabulary\"\n",
            "No esta en glove: \"word '147' not in vocabulary\"\n",
            "No esta en glove: \"word '148' not in vocabulary\"\n",
            "No esta en glove: \"word '149' not in vocabulary\"\n",
            "No esta en glove: \"word '15' not in vocabulary\"\n",
            "No esta en glove: \"word '150' not in vocabulary\"\n",
            "No esta en glove: \"word '151' not in vocabulary\"\n",
            "No esta en glove: \"word '153' not in vocabulary\"\n",
            "No esta en glove: \"word '154' not in vocabulary\"\n",
            "No esta en glove: \"word '155' not in vocabulary\"\n",
            "No esta en glove: \"word '157' not in vocabulary\"\n",
            "No esta en glove: \"word '158' not in vocabulary\"\n",
            "No esta en glove: \"word '16' not in vocabulary\"\n",
            "No esta en glove: \"word '163' not in vocabulary\"\n",
            "No esta en glove: \"word '164' not in vocabulary\"\n",
            "No esta en glove: \"word '165' not in vocabulary\"\n",
            "No esta en glove: \"word '166' not in vocabulary\"\n",
            "No esta en glove: \"word '17' not in vocabulary\"\n",
            "No esta en glove: \"word '176' not in vocabulary\"\n",
            "No esta en glove: \"word '177' not in vocabulary\"\n",
            "No esta en glove: \"word '179' not in vocabulary\"\n",
            "No esta en glove: \"word '18' not in vocabulary\"\n",
            "No esta en glove: \"word '180' not in vocabulary\"\n",
            "No esta en glove: \"word '182' not in vocabulary\"\n",
            "No esta en glove: \"word '186' not in vocabulary\"\n",
            "No esta en glove: \"word '188' not in vocabulary\"\n",
            "No esta en glove: \"word '189' not in vocabulary\"\n",
            "No esta en glove: \"word '192' not in vocabulary\"\n",
            "No esta en glove: \"word '193' not in vocabulary\"\n",
            "No esta en glove: \"word '195' not in vocabulary\"\n",
            "No esta en glove: \"word '196' not in vocabulary\"\n",
            "No esta en glove: \"word '1991' not in vocabulary\"\n",
            "No esta en glove: \"word '1993' not in vocabulary\"\n",
            "No esta en glove: \"word '2' not in vocabulary\"\n",
            "No esta en glove: \"word '20' not in vocabulary\"\n",
            "No esta en glove: \"word '200' not in vocabulary\"\n",
            "No esta en glove: \"word '2008' not in vocabulary\"\n",
            "No esta en glove: \"word '2009' not in vocabulary\"\n",
            "No esta en glove: \"word '201' not in vocabulary\"\n",
            "No esta en glove: \"word '201.4' not in vocabulary\"\n",
            "No esta en glove: \"word '203' not in vocabulary\"\n",
            "No esta en glove: \"word '204' not in vocabulary\"\n",
            "No esta en glove: \"word '205' not in vocabulary\"\n",
            "No esta en glove: \"word '211' not in vocabulary\"\n",
            "No esta en glove: \"word '213' not in vocabulary\"\n",
            "No esta en glove: \"word '219' not in vocabulary\"\n",
            "No esta en glove: \"word '222' not in vocabulary\"\n",
            "No esta en glove: \"word '223' not in vocabulary\"\n",
            "No esta en glove: \"word '224' not in vocabulary\"\n",
            "No esta en glove: \"word '225' not in vocabulary\"\n",
            "No esta en glove: \"word '226' not in vocabulary\"\n",
            "No esta en glove: \"word '228' not in vocabulary\"\n",
            "No esta en glove: \"word '229' not in vocabulary\"\n",
            "No esta en glove: \"word '23.83' not in vocabulary\"\n",
            "No esta en glove: \"word '231' not in vocabulary\"\n",
            "No esta en glove: \"word '232' not in vocabulary\"\n",
            "No esta en glove: \"word '233' not in vocabulary\"\n",
            "No esta en glove: \"word '236' not in vocabulary\"\n",
            "No esta en glove: \"word '237' not in vocabulary\"\n",
            "No esta en glove: \"word '238' not in vocabulary\"\n",
            "No esta en glove: \"word '24' not in vocabulary\"\n",
            "No esta en glove: \"word '240' not in vocabulary\"\n",
            "No esta en glove: \"word '241' not in vocabulary\"\n",
            "No esta en glove: \"word '242' not in vocabulary\"\n",
            "No esta en glove: \"word '243' not in vocabulary\"\n",
            "No esta en glove: \"word '244' not in vocabulary\"\n",
            "No esta en glove: \"word '246' not in vocabulary\"\n",
            "No esta en glove: \"word '247' not in vocabulary\"\n",
            "No esta en glove: \"word '25' not in vocabulary\"\n",
            "No esta en glove: \"word '251' not in vocabulary\"\n",
            "No esta en glove: \"word '255' not in vocabulary\"\n",
            "No esta en glove: \"word '256' not in vocabulary\"\n",
            "No esta en glove: \"word '257' not in vocabulary\"\n",
            "No esta en glove: \"word '258' not in vocabulary\"\n",
            "No esta en glove: \"word '260' not in vocabulary\"\n",
            "No esta en glove: \"word '265' not in vocabulary\"\n",
            "No esta en glove: \"word '277' not in vocabulary\"\n",
            "No esta en glove: \"word '281' not in vocabulary\"\n",
            "No esta en glove: \"word '282' not in vocabulary\"\n",
            "No esta en glove: \"word '3' not in vocabulary\"\n",
            "No esta en glove: \"word '30' not in vocabulary\"\n",
            "No esta en glove: \"word '31' not in vocabulary\"\n",
            "No esta en glove: \"word '318' not in vocabulary\"\n",
            "No esta en glove: \"word '32' not in vocabulary\"\n",
            "No esta en glove: \"word '320' not in vocabulary\"\n",
            "No esta en glove: \"word '321' not in vocabulary\"\n",
            "No esta en glove: \"word '322' not in vocabulary\"\n",
            "No esta en glove: \"word '324' not in vocabulary\"\n",
            "No esta en glove: \"word '328' not in vocabulary\"\n",
            "No esta en glove: \"word '33' not in vocabulary\"\n",
            "No esta en glove: \"word '333' not in vocabulary\"\n",
            "No esta en glove: \"word '337' not in vocabulary\"\n",
            "No esta en glove: \"word '34' not in vocabulary\"\n",
            "No esta en glove: \"word '36' not in vocabulary\"\n",
            "No esta en glove: \"word '360' not in vocabulary\"\n",
            "No esta en glove: \"word '374' not in vocabulary\"\n",
            "No esta en glove: \"word '375' not in vocabulary\"\n",
            "No esta en glove: \"word '376' not in vocabulary\"\n",
            "No esta en glove: \"word '377' not in vocabulary\"\n",
            "No esta en glove: \"word '382' not in vocabulary\"\n",
            "No esta en glove: \"word '389' not in vocabulary\"\n",
            "No esta en glove: \"word '390' not in vocabulary\"\n",
            "No esta en glove: \"word '391' not in vocabulary\"\n",
            "No esta en glove: \"word '392' not in vocabulary\"\n",
            "No esta en glove: \"word '393' not in vocabulary\"\n",
            "No esta en glove: \"word '395' not in vocabulary\"\n",
            "No esta en glove: \"word '4' not in vocabulary\"\n",
            "No esta en glove: \"word '40' not in vocabulary\"\n",
            "No esta en glove: \"word '401' not in vocabulary\"\n",
            "No esta en glove: \"word '402' not in vocabulary\"\n",
            "No esta en glove: \"word '403' not in vocabulary\"\n",
            "No esta en glove: \"word '404' not in vocabulary\"\n",
            "No esta en glove: \"word '406' not in vocabulary\"\n",
            "No esta en glove: \"word '407' not in vocabulary\"\n",
            "No esta en glove: \"word '408' not in vocabulary\"\n",
            "No esta en glove: \"word '41' not in vocabulary\"\n",
            "No esta en glove: \"word '411' not in vocabulary\"\n",
            "No esta en glove: \"word '412' not in vocabulary\"\n",
            "No esta en glove: \"word '416' not in vocabulary\"\n",
            "No esta en glove: \"word '42' not in vocabulary\"\n",
            "No esta en glove: \"word '43' not in vocabulary\"\n",
            "No esta en glove: \"word '437' not in vocabulary\"\n",
            "No esta en glove: \"word '44' not in vocabulary\"\n",
            "No esta en glove: \"word '44.1' not in vocabulary\"\n",
            "No esta en glove: \"word '45' not in vocabulary\"\n",
            "No esta en glove: \"word '45.10' not in vocabulary\"\n",
            "No esta en glove: \"word '452' not in vocabulary\"\n",
            "No esta en glove: \"word '455' not in vocabulary\"\n",
            "No esta en glove: \"word '48' not in vocabulary\"\n",
            "No esta en glove: \"word '49' not in vocabulary\"\n",
            "No esta en glove: \"word '4to' not in vocabulary\"\n",
            "No esta en glove: \"word '5' not in vocabulary\"\n",
            "No esta en glove: \"word '5.5' not in vocabulary\"\n",
            "No esta en glove: \"word '50' not in vocabulary\"\n",
            "No esta en glove: \"word '501' not in vocabulary\"\n",
            "No esta en glove: \"word '51' not in vocabulary\"\n",
            "No esta en glove: \"word '51.3' not in vocabulary\"\n",
            "No esta en glove: \"word '51.5' not in vocabulary\"\n",
            "No esta en glove: \"word '52' not in vocabulary\"\n",
            "No esta en glove: \"word '2004' not in vocabulary\"\n",
            "No esta en glove: \"word '54' not in vocabulary\"\n",
            "No esta en glove: \"word '56' not in vocabulary\"\n",
            "No esta en glove: \"word '58' not in vocabulary\"\n",
            "No esta en glove: \"word '6' not in vocabulary\"\n",
            "No esta en glove: \"word '60' not in vocabulary\"\n",
            "No esta en glove: \"word '62' not in vocabulary\"\n",
            "No esta en glove: \"word '63' not in vocabulary\"\n",
            "No esta en glove: \"word '67' not in vocabulary\"\n",
            "No esta en glove: \"word '68' not in vocabulary\"\n",
            "No esta en glove: \"word '683' not in vocabulary\"\n",
            "No esta en glove: \"word '701,703' not in vocabulary\"\n",
            "No esta en glove: \"word '702' not in vocabulary\"\n",
            "No esta en glove: \"word '703' not in vocabulary\"\n",
            "No esta en glove: \"word '704' not in vocabulary\"\n",
            "No esta en glove: \"word '712' not in vocabulary\"\n",
            "No esta en glove: \"word '715' not in vocabulary\"\n",
            "No esta en glove: \"word '72' not in vocabulary\"\n",
            "No esta en glove: \"word '720' not in vocabulary\"\n",
            "No esta en glove: \"word '721' not in vocabulary\"\n",
            "No esta en glove: \"word '73' not in vocabulary\"\n",
            "No esta en glove: \"word '74' not in vocabulary\"\n",
            "No esta en glove: \"word '75' not in vocabulary\"\n",
            "No esta en glove: \"word '75.1' not in vocabulary\"\n",
            "No esta en glove: \"word '75.3' not in vocabulary\"\n",
            "No esta en glove: \"word '75.4' not in vocabulary\"\n",
            "No esta en glove: \"word '76' not in vocabulary\"\n",
            "No esta en glove: \"word '79' not in vocabulary\"\n",
            "No esta en glove: \"word '80' not in vocabulary\"\n",
            "No esta en glove: \"word '82' not in vocabulary\"\n",
            "No esta en glove: \"word '82.1' not in vocabulary\"\n",
            "No esta en glove: \"word '82.2' not in vocabulary\"\n",
            "No esta en glove: \"word '85' not in vocabulary\"\n",
            "No esta en glove: \"word '86' not in vocabulary\"\n",
            "No esta en glove: \"word '87' not in vocabulary\"\n",
            "No esta en glove: \"word '88' not in vocabulary\"\n",
            "No esta en glove: \"word '88.18' not in vocabulary\"\n",
            "No esta en glove: \"word '93' not in vocabulary\"\n",
            "No esta en glove: \"word '94' not in vocabulary\"\n",
            "No esta en glove: \"word '95' not in vocabulary\"\n",
            "No esta en glove: \"word '96' not in vocabulary\"\n",
            "No esta en glove: \"word '98' not in vocabulary\"\n",
            "No esta en glove: \"word ':' not in vocabulary\"\n",
            "No esta en glove: \"word 'aquienes' not in vocabulary\"\n",
            "No esta en glove: \"word 'laborabot' not in vocabulary\"\n",
            "No esta en glove: \"word 'amonestacion' not in vocabulary\"\n",
            "No esta en glove: \"word 'art.110' not in vocabulary\"\n",
            "No esta en glove: \"word 'art.17' not in vocabulary\"\n",
            "No esta en glove: \"word 'art.177' not in vocabulary\"\n",
            "No esta en glove: \"word 'art.19' not in vocabulary\"\n",
            "No esta en glove: \"word 'art.222' not in vocabulary\"\n",
            "No esta en glove: \"word 'art.258' not in vocabulary\"\n",
            "No esta en glove: \"word 'art.5' not in vocabulary\"\n",
            "No esta en glove: \"word 'art.50' not in vocabulary\"\n",
            "No esta en glove: \"word 'art.75' not in vocabulary\"\n",
            "No esta en glove: \"word 'arts.197' not in vocabulary\"\n",
            "No esta en glove: \"word 'bien,¿cómo' not in vocabulary\"\n",
            "No esta en glove: \"word 'calcularle' not in vocabulary\"\n",
            "No esta en glove: \"word 'contra.artículos' not in vocabulary\"\n",
            "No esta en glove: \"word 'coraasan' not in vocabulary\"\n",
            "No esta en glove: \"word 'ct.aparte' not in vocabulary\"\n",
            "No esta en glove: \"word 'ct.b' not in vocabulary\"\n",
            "No esta en glove: \"word 'ct.también' not in vocabulary\"\n",
            "No esta en glove: \"word 'cuándose' not in vocabulary\"\n",
            "No esta en glove: \"word 'derechos:' not in vocabulary\"\n",
            "No esta en glove: \"word 'desahuciarla' not in vocabulary\"\n",
            "No esta en glove: \"word 'desahuciarme' not in vocabulary\"\n",
            "No esta en glove: \"word 'desahucie' not in vocabulary\"\n",
            "No esta en glove: \"word 'desahucien' not in vocabulary\"\n",
            "No esta en glove: \"word 'descontarme' not in vocabulary\"\n",
            "No esta en glove: \"word 'dimisiónlas' not in vocabulary\"\n",
            "No esta en glove: \"word 'economina' not in vocabulary\"\n",
            "No esta en glove: \"word 'efermedad' not in vocabulary\"\n",
            "No esta en glove: \"word 'empleador.artículos' not in vocabulary\"\n",
            "No esta en glove: \"word 'formalicemos' not in vocabulary\"\n",
            "No esta en glove: \"word 'fuerza.e' not in vocabulary\"\n",
            "No esta en glove: \"word 'inminentes.b' not in vocabulary\"\n",
            "No esta en glove: \"word 'intimarán' not in vocabulary\"\n",
            "No esta en glove: \"word 'lecencia' not in vocabulary\"\n",
            "No esta en glove: \"word 'ley.' not in vocabulary\"\n",
            "No esta en glove: \"word 'meses;' not in vocabulary\"\n",
            "No esta en glove: \"word 'natal;' not in vocabulary\"\n",
            "No esta en glove: \"word 'no.' not in vocabulary\"\n",
            "No esta en glove: \"word 'no.00157' not in vocabulary\"\n",
            "No esta en glove: \"word 'no.00172' not in vocabulary\"\n",
            "No esta en glove: \"word 'no.41' not in vocabulary\"\n",
            "No esta en glove: \"word 'normal.c' not in vocabulary\"\n",
            "No esta en glove: \"word 'normal.d' not in vocabulary\"\n",
            "No esta en glove: \"word 'opciones:' not in vocabulary\"\n",
            "No esta en glove: \"word 'permitidos:' not in vocabulary\"\n",
            "No esta en glove: \"word 'porcertaje' not in vocabulary\"\n",
            "No esta en glove: \"word 'prerrogativas:' not in vocabulary\"\n",
            "No esta en glove: \"word 'privados.art' not in vocabulary\"\n",
            "No esta en glove: \"word 'prohibido.la' not in vocabulary\"\n",
            "No esta en glove: \"word '1,000.00' not in vocabulary\"\n",
            "No esta en glove: \"word '2,000.00' not in vocabulary\"\n",
            "No esta en glove: \"word '200.00' not in vocabulary\"\n",
            "No esta en glove: \"word '500.00' not in vocabulary\"\n",
            "No esta en glove: \"word 'reglasa' not in vocabulary\"\n",
            "No esta en glove: \"word '“cuando' not in vocabulary\"\n",
            "No esta en glove: \"word 'rendida“salario' not in vocabulary\"\n",
            "No esta en glove: \"word 'salario.' not in vocabulary\"\n",
            "No esta en glove: \"word 'sisalril' not in vocabulary\"\n",
            "No esta en glove: \"word 'tardes,¿cómo' not in vocabulary\"\n",
            "No esta en glove: \"word 'tiempo;' not in vocabulary\"\n",
            "No esta en glove: \"word 'tomarian' not in vocabulary\"\n",
            "No esta en glove: \"word 'trabajo.' not in vocabulary\"\n",
            "No esta en glove: \"word 'trabajo.en' not in vocabulary\"\n",
            "No esta en glove: \"word 'vencieren' not in vocabulary\"\n",
            "No esta en glove: \"word '¿' not in vocabulary\"\n",
            "No esta en glove: \"word '“' not in vocabulary\"\n",
            "No esta en glove: \"word '”' not in vocabulary\"\n",
            "No esta en glove: \"word '”aplicando' not in vocabulary\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw-7_ZtsYA1_",
        "colab_type": "code",
        "outputId": "b45b7497-8c62-4442-f12d-24269479a5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_output_data,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        "    batch_size=32,\n",
        "    epochs=110,\n",
        ")\n",
        "\n",
        "# print(history.history['loss'])\n",
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['val_loss'])\n",
        "pyplot.title('model train vs validation loss')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'validation'], loc='upper right')\n",
        "pyplot.show()\n",
        "\n",
        "pyplot.plot(history.history['val_accuracy'])\n",
        "pyplot.plot(history.history['accuracy'])\n",
        "pyplot.title('model train vs validation accuracy')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'validation'], loc='upper right')\n",
        "pyplot.show()\n",
        "\n",
        "model.save(\"model.h5\")\n",
        "\n",
        "\n",
        "def make_inference_models():\n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=(300,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=(300,))\n",
        "\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding, initial_state=decoder_states_inputs\n",
        "    )\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "\n",
        "\n",
        "def str_to_tokens(sentence: str):\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for word in words:\n",
        "        tokens_list.append(tokenizer.word_index[word])\n",
        "    return preprocessing.sequence.pad_sequences(\n",
        "        [tokens_list], maxlen=maxlen_questions, padding=\"post\"\n",
        "    )\n",
        "\n",
        "\n",
        "enc_model, dec_model = make_inference_models()\n",
        "\n",
        "for _ in range(10000):\n",
        "    states_values = enc_model.predict(str_to_tokens(input(\"Enter question : \")))\n",
        "    empty_target_seq = np.zeros((1, 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index[\"start\"]\n",
        "    stop_condition = False\n",
        "    decoded_translation = \"\"\n",
        "    while not stop_condition:\n",
        "        dec_outputs, h, c = dec_model.predict([empty_target_seq] + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if sampled_word_index == index:\n",
        "                decoded_translation += \" {}\".format(word)\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == \"end\":\n",
        "            stop_condition = True\n",
        "\n",
        "        empty_target_seq = np.zeros((1, 1))\n",
        "        empty_target_seq[0, 0] = sampled_word_index\n",
        "        states_values = [h, c]\n",
        "\n",
        "    print(decoded_translation)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d9da65261370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit(\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdecoder_output_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}